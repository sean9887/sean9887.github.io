---
published: true
layout: post
title: "자율주행 데이터셋 구축"
categories: [Project]
tags: [Autonomous Driving]
---

## 1. 프로젝트 설계

- 목표
자율주행 AI 모델 학습에 필요한 고품질 센서 데이터셋(영상 + 라이다)을 구축하여, 객체 탐지 및 인식 알고리즘의 정밀도 향상을 지원

- 범위
다양한 시간대와 기상 조건에서의 주행 데이터를 확보하고, 이를 기반으로 객체 중심의 라벨링 및 센서 정합 처리를 거쳐 완성도 높은 데이터셋 구축

## 2. 데이터 수집

- 수집 도구

    - 라이더(LiDAR) + 카메라 탑재 차량 
    - 탑재 카메라 대수 : 총 4대(LH, RH, FR, RR)

- 수집 방법

    - 카메라 탑재 차량으로 하루 8시간씩 주행
    - 상황 별 주행 데이터 수집  : 밤, 낮, 날씨(구름, 비, 맑음)

## 3. 수집 데이터 처리 방안

- 동기화 처리
    - LiDAR와 Camera 간 Timestamp 정렬
    - GPS/IMU 데이터 기반으로 프레임 정렬 및 위치 보정

- 포맷 변환
    - Raw Sensor Data → 정제된 파일 구조로 변환 (PNG, JSON)

- 저장 구조
    - 프레임 단위로 정리된 디렉토리 구조 생성 (예: /2022_03_01/000001/)

- 전처리
    - 센서 정렬 및 캘리브레이션 적용
        - 수집된 PCD(Point Cloud) 데이터에 Camera–LiDAR 간 캘리브레이션 정보 적용
        - Extrinsic/Intrinsic 파라미터를 기반으로 좌표계 정렬 및 시야각 정합
    - 데이터 업로드 처리
        - 보정된 이미지 및 PCD 데이터를 회사 내 어노테이션 플랫폼 포맷에 맞게 변환
        - 시나리오, 주행 정보, 센서 정보 포함한 메타데이터 구성 후 자동 업로드
    - 파일 구조 및 관리
        - 프레임 단위 폴더 구조로 구성 (/날짜/프레임번호/)
        - 각 프레임에 대해 이미지, 포인트클라우드, 캘리브레이션, 메타 정보 포함

- 자동화 파이프라인 (Airflow)
    - Airflow를 활용하여 대량의 수집 데이터를 자동으로 처리
    - 데이터 유입 시, 프레임 단위로 분할 후 시나리오, 날씨, 시간 등 메타 정보를 포함한 폴더 트리 구조 생성
    - 라벨링 시스템과 연계 가능한 형식으로 자동 업로드 처리
    - 각 프레임의 메타 정보에 라벨링 기준 정보를 포함하여 작업자가 직접 확인해야 할 항목 최소화
    - 전처리 및 메타 정보 생성 완료 후, 프레임 단위 데이터를 S3 버킷에 업로드
    <img src="/assets/img/airflow_dags.png" alt="dags" width="80%"/>


## 4. 데이터 정제(Curation)

- 불량 데이터 제거

    - 센서 오류, 흐림/역광 등 판독 불가 프레임 필터링

- 라벨 기준 정의

    - 클래스 정의: 차량, 보행자, 자전거, 신호등, 표지판 등
    - 라벨링 일관성 확보를 위한 가이드라인 배포 및 검수 기준 수립

- 시나리오 기반 필터링

    - 특정 상황(예: 야간 교차로, 비오는 고속도로)의 균형적 분포 확보

## 5. 데이터 가공

- 객체 라벨링

    - 2D 라벨링: 이미지에 Bounding Box 및 클래스 정보 부여
    - 3D 라벨링: PCD 데이터에 3D Box 및 위치/방향 정보 부여

- 센서 정합

    - 3D Box를 Camera View로 Projection하여 정합도 확인
    - 이미지와 PCD 객체 간 유사도 기반 Matching 수행

- 자동화 파이프라인

    - 일부 객체에 대해 모델 기반 Pre-labeling 후 검수 보조

## 6. 데이터 검수

- 내부 품질 기준 기반 수동 검수

    - 라벨 오분류, 객체 id 오류, 박스 크기 불일치, 센서 정합 오류 등 확인

- 정합 검수

    - 2D/3D 정합 시각화 UI를 통해 센서 정합 정확도 확인
    - 기준 미달 시 재작업 플래그 처리

- 다단계 검수 프로세스

    - Annotator → Reviewer → 관리자 순 검수
    - 오류 이력 관리 및 개선 피드백 순환 구조

## 7. 데이터 후처리

- 이미지 라벨링 결과
    - 클래스, 2d bounding box 좌표(x,y,width,height), 객체 id 등

- PCD 라벨링 결과
    - 클래스, 3d bounding box 좌표(x,y,z,w,h,l), 객체 id 등

- 센서 퓨전 데이터
    - 이미지(Camera)와 PCD(LiDAR) 라벨 데이터를 센서 퓨전 기반으로 정합(Matching)하여, 통합된 객체 정보(JSON 파일)로 후처리
    - 배치마다 센서 퓨전 데이터 및 마스킹 데이터 산출물로 생성

## 8. 모델 재학습 및 데이터 배치별 납품

- 모델 재학습

    - 라벨링 완료된 데이터를 바탕으로 객체 탐지 모델 재학습
    - 모델 성능 저하 시, 추가 수집/정제를 통해 데이터 보완

- 데이터 배치 단위 납품

    - 납품 주기: 주간 또는 월간 단위
    - 납품 형식: 배치별 JSON 메타데이터, 정합 결과 이미지, Segmentation 마스크 이미지

## 9. 결론: End-to-End 데이터 프로젝트의 인사이트

이번 프로젝트를 통해 자율주행 AI 모델 학습을 위한 데이터셋 구축을 단순한 수집과 라벨링을 넘어, **자동화된 파이프라인 설계부터 후처리 및 납품까지 End-to-End로 경험**할 수 있었음

특히 수천~수만 프레임 단위의 대규모 데이터를 다루며 다음과 같은 중요한 인사이트를 얻음

- **Airflow 기반 자동화 파이프라인**을 구축함으로써, 데이터 유입 시 자동으로 프레임을 분할하고 메타 정보를 포함한 폴더 구조를 생성하여 작업자의 수작업 부담을 획기적으로 줄일 수 있었음
- 가공된 데이터는 **S3 버킷에 업로드되어 어노테이션 플랫폼과 연동**되며, 메타 정보 기반으로 자동 작업 생성 및 필터링 기능이 동작해 **협업과 운영 효율이 크게 향상**되었음
- 센서 정합 오류, 라벨 오분류 등 다양한 품질 이슈를 **시각화 UI와 다단계 검수 체계를 통해 반복 개선**하며, 데이터셋의 신뢰도를 확보할 수 있었음
- 이러한 과정을 통해, **어노테이션 툴은 단순한 라벨링 도구가 아닌 전체 데이터 파이프라인의 허브로 기능해야 한다는 인식**을 하게 되었고,
  라벨러의 피로도를 줄이고 정합 품질을 높이기 위한 기능(정합률 기반 시각화, 메타 정보 필터링, auto 라벨링 등)이 필수적으로 포함되어야 함을 체감함

이처럼 데이터를 다루는 전 주기를 실무적으로 경험하며, 단순히 데이터를 라벨링하는 수준을 넘어, **AI 모델 학습을 위한 실질적이고 확장 가능한 데이터 인프라**가 어떻게 설계되어야 하는지를 구체적으로 배울 수 있는 프로젝트였음
